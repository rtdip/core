{
  "run_timestamp": "2025-11-18T10:10:23.124499",
  "autogluon_training_time_seconds": 158.553592,
  "lstm_training_time_seconds": 4016.378132,
  "xgboost_training_time_seconds": 195.803674,
  "num_sensors": 9,
  "prediction_length": 24,
  "train_ratio": 0.7,
  "val_ratio": 0.15,
  "test_ratio": 0.15,
  "freq": "h",
  "eval_metric": "MAE",
  "data_split": {
    "train_start": "2023-12-31T00:00:00.039000",
    "train_end": "2024-07-16T18:24:23.085000",
    "val_start": "2024-01-20T23:58:40.133000",
    "val_end": "2024-07-22T00:32:08.058000",
    "test_start": "2024-01-25T11:59:55.110000",
    "test_end": "2024-07-27T23:59:57.573000",
    "train_samples": 3289822,
    "val_samples": 704967,
    "test_samples": 704967
  },
  "model_configs": {
    "lstm": {
      "lookback_window": 72,
      "lstm_units": 48,
      "num_lstm_layers": 2,
      "batch_size": 512,
      "epochs": 10,
      "patience": 5
    },
    "xgboost": {
      "max_depth": 5,
      "learning_rate": 0.05,
      "n_estimators": 150,
      "lag_features": [
        1,
        6,
        12,
        24,
        48
      ],
      "rolling_windows": [
        12,
        24
      ]
    }
  },
  "notes": {
    "models": "Comparison includes AutoGluon (ensemble), LSTM (single model with sensor embeddings), and XGBoost (gradient boosting with feature engineering)",
    "predictions": "All models generate future forecasts (prediction_length steps beyond test set).",
    "autogluon_predictions": "AutoGluon predictions are future forecasts from ensemble.",
    "lstm_predictions": "LSTM predictions are future forecasts from single model with sensor embeddings.",
    "xgboost_predictions": "XGBoost predictions are recursive forecasts with engineered lag features."
  }
}