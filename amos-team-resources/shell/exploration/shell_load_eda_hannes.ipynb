{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18092304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HADOOP_HOME'] = r'C:\\hadoop'\n",
    "os.environ['PATH'] = os.environ['HADOOP_HOME'] + r'\\bin;' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3244e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import pyarrow\n",
    "import tempfile\n",
    "import gc\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType\n",
    "from pyspark.sql.functions import col, when, isnan\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb48e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sas_token = \"xxx\"\n",
    "\n",
    "account_url = \"xxx\"\n",
    "\n",
    "container_name = \"xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ccf2811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BlobServiceClient using the SAS token\n",
    "blob_service_client = BlobServiceClient(account_url=account_url, credential=sas_token)\n",
    "\n",
    "# Get the container client\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# List all blobs in the container\n",
    "#for blob in container_client.list_blobs():\n",
    "#    print(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599079c0",
   "metadata": {},
   "source": [
    "## Spark Load (problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3dd5961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"AzureParquetToDelta\")\n",
    "    .config(\"spark.driver.memory\", \"16g\")      \n",
    "    .config(\"spark.executor.memory\", \"16g\")    \n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac258d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List blobs and read them directly as Spark DataFrames\n",
    "temp_files = []\n",
    "\n",
    "for blob in container_client.list_blobs():\n",
    "    blob_client = container_client.get_blob_client(blob)\n",
    "    data = blob_client.download_blob().readall()\n",
    "\n",
    "    # Skip empty downloads\n",
    "    #if len(data) == 0:\n",
    "    #    print(f\"Skipped empty blob: {blob.name}\")\n",
    "    #    continue\n",
    "\n",
    "    # Save to temp file\n",
    "    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".parquet\")\n",
    "    tmp.write(data)\n",
    "    tmp.close()\n",
    "    temp_files.append(tmp.name)\n",
    "\n",
    "#schema = StructType([\n",
    "#    StructField(\"TagName\", StringType(), True),\n",
    "#    StructField(\"EventTime\", TimestampType(), True),\n",
    "#    StructField(\"Status\", StringType(), True),\n",
    "#    StructField(\"Value\", StringType(), True)  # <- force string at read time\n",
    "#])\n",
    "\n",
    "# Read all temp Parquet files in Spark\n",
    "spark_df = spark.read.parquet(*temp_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25a51538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n",
    "#spark_df = spark.read.option(\"mergeSchema\", \"true\").parquet(*temp_files)\n",
    "#spark_df = spark.read.parquet(*temp_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b860fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+------+----------+\n",
      "|         TagName|           EventTime|Status|     Value|\n",
      "+----------------+--------------------+------+----------+\n",
      "| :V0V8C5DP67P0.P|2024-07-05 18:01:...|  Good|0.06322985|\n",
      "|O49TPU05CV86.CP:|2024-07-05 20:48:...|  Good|  96.24695|\n",
      "| 6I.:V9L8P0VCP96|2024-07-06 01:24:...|  Good| 38.797314|\n",
      "| .LC6P6V:P0I918V|2024-07-05 14:41:...|  Good|  170.4655|\n",
      "|  V.P301:PV807CX|2024-07-05 10:12:...|  Good| 1002.4146|\n",
      "+----------------+--------------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- TagName: string (nullable = true)\n",
      " |-- EventTime: timestamp (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Value: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(5)\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a69b53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- TagName: string (nullable = true)\n",
      " |-- EventTime: timestamp (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#spark_df = spark_df.withColumn(\"Value\",col(\"Value\").cast(StringType()))\n",
    "\n",
    "spark_df = spark_df.withColumn(\n",
    "    \"Value\",\n",
    "    when(col(\"Value\").isNull(), None)\n",
    "    .when(isnan(col(\"Value\")), \"NaN\")\n",
    "    .otherwise(col(\"Value\").cast(StringType()))\n",
    ")\n",
    "\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2011a275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta table will be stored at: C:\\Users\\Agando\\Documents\\Projects\\amos2025ws03-rtdip-timeseries-forecasting\\dummy\\data\\delta\\shell_data\n"
     ]
    }
   ],
   "source": [
    "delta_path = os.path.abspath(\"data/delta/shell_data\")\n",
    "delta_path = Path(delta_path).resolve()\n",
    "delta_uri = delta_path.as_uri()\n",
    "\n",
    "print(f\"Delta table will be stored at: {delta_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8edac324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_parquet = \"C:/temp/intermediate.parquet\"\n",
    "#spark_df.write.mode(\"overwrite\").parquet(temp_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a233bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark_df.write.format(\"delta\").mode(\"overwrite\").save(delta_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b10dbec",
   "metadata": {},
   "source": [
    "## Pandas Load & Store as Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad946e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_1\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_10\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_11\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_12\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_13\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_14\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_15\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_16\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_17\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_18\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_19\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_2\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_20\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_21\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_22\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_23\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_24\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_25\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_26\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_27\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_28\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_29\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_3\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_30\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_31\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_32\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_33\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_34\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_35\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_36\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_37\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_38\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_39\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_4\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_40\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_41\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_42\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_43\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_44\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_45\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_46\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_47\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_48\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_49\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_5\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_50\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_51\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_52\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_53\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_54\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_55\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_56\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_57\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_58\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_59\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_6\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_60\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_61\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_62\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_63\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_7\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_8\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:02:10.442377.parquet_DataFrame_9\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_1\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_10\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_11\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_12\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_13\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_14\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_15\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_16\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_17\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_18\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_19\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_2\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_20\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_21\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_22\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_23\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_24\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_25\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_26\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_27\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_28\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_29\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_3\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_30\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_31\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_32\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_33\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_34\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_35\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_36\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_37\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_38\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_39\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_4\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_40\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_41\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_42\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_43\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_44\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_45\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_46\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_47\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_48\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_49\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_5\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_50\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_51\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_52\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_53\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_54\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_55\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_56\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_57\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_58\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_59\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_6\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_60\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_61\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_62\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_7\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_8\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:05:44.319915.parquet_DataFrame_9\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_1\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_10\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_11\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_12\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_13\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_14\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_15\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_16\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_17\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_18\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_19\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_2\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_20\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_21\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_22\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_23\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_24\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_25\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_26\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_27\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_28\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_29\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_3\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_30\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_31\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_32\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_33\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_34\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_35\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_36\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_37\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_38\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_39\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_4\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_40\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_41\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_42\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_43\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_44\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_45\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_46\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_47\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_48\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_49\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_5\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_50\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_51\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_52\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_53\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_54\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_55\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_56\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_57\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_58\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_59\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_6\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_60\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_61\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_7\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_8\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:08:53.060991.parquet_DataFrame_9\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_1\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_10\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_11\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_12\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_13\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_14\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_15\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_16\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_17\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_18\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_19\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_2\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_20\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_21\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_22\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_23\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_24\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_25\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_26\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_27\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_28\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_29\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_3\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_30\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_31\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_32\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_33\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_34\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_35\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_36\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_37\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_38\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_39\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_4\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_40\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_41\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_42\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_43\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_44\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_45\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_46\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_47\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_48\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_49\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_5\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_50\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_51\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_52\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_53\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_54\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_55\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_56\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_57\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_58\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_59\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_6\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_60\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_61\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_7\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_8\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:12:09.072543.parquet_DataFrame_9\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_1\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_10\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_11\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_12\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_13\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_14\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_15\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_16\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_17\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_18\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_19\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_2\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_20\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_21\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_22\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_23\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_24\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_25\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_26\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_27\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_28\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_29\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_3\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_30\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_31\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_32\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_33\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_34\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_35\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_36\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_37\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_38\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_39\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_4\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_40\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_41\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_42\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_43\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_44\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_45\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_46\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_47\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_48\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_49\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_5\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_50\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_51\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_52\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_53\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_54\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_55\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_56\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_57\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_58\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_59\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_6\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_60\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_61\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_7\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_8\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:15:27.033460.parquet_DataFrame_9\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_1\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_10\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_11\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_12\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_13\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_14\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_15\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_16\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_17\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_18\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_19\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_2\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_20\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_21\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_22\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_23\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_24\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_25\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_26\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_27\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_28\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_29\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_3\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_30\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_31\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_32\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_33\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_34\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_35\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_36\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_37\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_38\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_39\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_4\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_40\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_41\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_42\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_43\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_44\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_45\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_46\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_47\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_48\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_49\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_5\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_50\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_51\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_52\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_53\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_54\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_55\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_56\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_57\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_58\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_59\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_6\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_60\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_61\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_7\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_8\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:18:48.679350.parquet_DataFrame_9\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_1\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_10\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_11\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_12\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_13\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_14\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_15\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_16\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_17\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_18\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_19\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_2\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_20\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_21\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_22\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_23\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_24\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_25\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_26\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_27\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_28\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_29\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_3\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_30\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_31\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_32\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_33\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_34\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_35\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_36\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_37\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_38\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_39\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_4\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_40\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_41\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_42\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_43\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_44\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_45\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_46\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_47\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_48\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_49\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_5\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_50\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_51\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_52\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_53\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_54\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_55\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_56\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_57\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_58\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_59\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_6\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_60\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_7\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_8\n",
      "Reading: Data/2024/TagMeasurements_float_2024-10-10 06:22:02.458999.parquet_DataFrame_9\n",
      "Reading: Data/2024/TagMeasurements_string_2024-10-10 06:05:44.319928.parquet_DataFrame_1\n",
      "Reading: Data/2024/TagMeasurements_string_2024-10-10 06:08:53.061006.parquet_DataFrame_1\n",
      "Reading: Data/2024/TagMeasurements_string_2024-10-10 06:12:09.072556.parquet_DataFrame_1\n",
      "Reading: Data/2024/TagMeasurements_string_2024-10-10 06:15:27.033478.parquet_DataFrame_1\n",
      "Reading: Data/2024/TagMeasurements_string_2024-10-10 06:18:48.679364.parquet_DataFrame_1\n",
      "Reading: Data/2024/TagMeasurements_string_2024-10-10 06:22:02.459012.parquet_DataFrame_1\n",
      "\n",
      "Loaded 435 dataframes.\n",
      "Combined dataframe shape: (214991102, 4)\n"
     ]
    }
   ],
   "source": [
    "dataframes = []\n",
    "\n",
    "for blob in container_client.list_blobs():\n",
    "    # Match filenames containing '.parquet'\n",
    "    if \".parquet\" in blob.name.lower():\n",
    "        print(f\"Reading: {blob.name}\")\n",
    "        blob_client = container_client.get_blob_client(blob)\n",
    "        try:\n",
    "            stream = blob_client.download_blob()\n",
    "            data = stream.readall()\n",
    "            df = pd.read_parquet(BytesIO(data))\n",
    "            \n",
    "            # Optional: add filename info\n",
    "            #df[\"source_file\"] = blob.name\n",
    "            \n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {blob.name}: {e}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(dataframes)} dataframes.\")\n",
    "\n",
    "if dataframes:\n",
    "    pd_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(\"Combined dataframe shape:\", pd_df.shape)\n",
    "else:\n",
    "    print(\"No dataframes were loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "164748dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214991102 entries, 0 to 214991101\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype         \n",
      "---  ------     -----         \n",
      " 0   TagName    object        \n",
      " 1   EventTime  datetime64[ns]\n",
      " 2   Status     object        \n",
      " 3   Value      object        \n",
      "dtypes: datetime64[ns](1), object(3)\n",
      "memory usage: 6.4+ GB\n"
     ]
    }
   ],
   "source": [
    "pd_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a3619b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TagName</th>\n",
       "      <th>EventTime</th>\n",
       "      <th>Status</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2PS64V0J.:ZUX09R</td>\n",
       "      <td>2024-01-02 20:03:46</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2PS64V0J.:ZUX09R</td>\n",
       "      <td>2024-01-02 16:00:12</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2PS64V0J.:ZUX09R</td>\n",
       "      <td>2024-01-02 11:56:42</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2PS64V0J.:ZUX09R</td>\n",
       "      <td>2024-01-02 07:53:11</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2PS64V0J.:ZUX09R</td>\n",
       "      <td>2024-01-02 03:49:45</td>\n",
       "      <td>Good</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TagName           EventTime Status Value\n",
       "0  A2PS64V0J.:ZUX09R 2024-01-02 20:03:46   Good  0.34\n",
       "1  A2PS64V0J.:ZUX09R 2024-01-02 16:00:12   Good  0.15\n",
       "2  A2PS64V0J.:ZUX09R 2024-01-02 11:56:42   Good  0.13\n",
       "3  A2PS64V0J.:ZUX09R 2024-01-02 07:53:11   Good  0.12\n",
       "4  A2PS64V0J.:ZUX09R 2024-01-02 03:49:45   Good  0.13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c23e3ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric values count: 565,977\n",
      "\n",
      "Unique non-numeric values:\n",
      "Value\n",
      "Calc Failed      231627\n",
      "Bad Input         98155\n",
      "No Result         47516\n",
      "Failed            47516\n",
      "Out of Serv       43917\n",
      "Bad               19920\n",
      "Scan Timeout       1452\n",
      "Comm Fail           694\n",
      "I/O Timeout         208\n",
      "Doubtful             41\n",
      "Not Connect          34\n",
      "Pt Created           12\n",
      "Invalid Float         8\n",
      "Scan Off              2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample rows with non-numeric values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TagName</th>\n",
       "      <th>EventTime</th>\n",
       "      <th>Status</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>575872</th>\n",
       "      <td>1530P2X:VUC0.HB</td>\n",
       "      <td>2024-01-15 09:24:00</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575924</th>\n",
       "      <td>1530P2X:VUC0.HB</td>\n",
       "      <td>2024-01-15 09:22:00</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577989</th>\n",
       "      <td>1530P2X:VUC0.HB</td>\n",
       "      <td>2024-01-15 12:59:00</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577992</th>\n",
       "      <td>1530P2X:VUC0.HB</td>\n",
       "      <td>2024-01-15 12:57:00</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580091</th>\n",
       "      <td>1530P2X:VUC0.HB</td>\n",
       "      <td>2024-01-15 12:58:00</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580298</th>\n",
       "      <td>1530P2X:VUC0.HB</td>\n",
       "      <td>2024-01-15 09:20:00</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581125</th>\n",
       "      <td>1530P2X:VUC0.HB</td>\n",
       "      <td>2024-01-15 09:23:00</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581209</th>\n",
       "      <td>1530P2X:VUC0.HB</td>\n",
       "      <td>2024-01-15 09:18:00</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581908</th>\n",
       "      <td>1530P2X:VUC0.HB</td>\n",
       "      <td>2024-01-15 07:04:00</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582059</th>\n",
       "      <td>1530P2X:VUC0.HB</td>\n",
       "      <td>2024-01-15 07:05:00</td>\n",
       "      <td>Bad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TagName           EventTime Status Value\n",
       "575872  1530P2X:VUC0.HB 2024-01-15 09:24:00    Bad   NaN\n",
       "575924  1530P2X:VUC0.HB 2024-01-15 09:22:00    Bad   NaN\n",
       "577989  1530P2X:VUC0.HB 2024-01-15 12:59:00    Bad   NaN\n",
       "577992  1530P2X:VUC0.HB 2024-01-15 12:57:00    Bad   NaN\n",
       "580091  1530P2X:VUC0.HB 2024-01-15 12:58:00    Bad   NaN\n",
       "580298  1530P2X:VUC0.HB 2024-01-15 09:20:00    Bad   NaN\n",
       "581125  1530P2X:VUC0.HB 2024-01-15 09:23:00    Bad   NaN\n",
       "581209  1530P2X:VUC0.HB 2024-01-15 09:18:00    Bad   NaN\n",
       "581908  1530P2X:VUC0.HB 2024-01-15 07:04:00    Bad   NaN\n",
       "582059  1530P2X:VUC0.HB 2024-01-15 07:05:00    Bad   NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_numeric = pd_df[pd.to_numeric(pd_df['Value'], errors='coerce').isna()]\n",
    "\n",
    "print(f\"Non-numeric values count: {len(non_numeric):,}\")\n",
    "print(f\"\\nUnique non-numeric values:\")\n",
    "print(non_numeric['Value'].value_counts())\n",
    "\n",
    "print(f\"\\nSample rows with non-numeric values:\")\n",
    "non_numeric[['TagName', 'EventTime', 'Status', 'Value']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72f0fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TagName      0\n",
       "EventTime    0\n",
       "Status       0\n",
       "Value        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Missing values:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed59492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_df = pd.read_parquet(\"data/shell.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2e2fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To prevent any type errors / conflicts with spark\n",
    "pd_df = pd_df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c3ba3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df.to_parquet(\"data/shell.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3abc6e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4914"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del pd_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f6b14",
   "metadata": {},
   "source": [
    "## EDA in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "703f3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"AzureParquetToDelta\")\n",
    "    .config(\"spark.driver.memory\", \"16g\")      \n",
    "    .config(\"spark.executor.memory\", \"16g\")    \n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2cff78e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.read.parquet(\"data/shell.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa8b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 214,991,102\n",
      "\n",
      "Schema:\n",
      "root\n",
      " |-- TagName: string (nullable = true)\n",
      " |-- EventTime: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Value: string (nullable = true)\n",
      "\n",
      "\n",
      "DataFrame info:\n",
      "Number of partitions: 22\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BASIC INFO & SHAPE\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"Total rows: {spark_df.count():,}\")\n",
    "print(f\"\\nSchema:\")\n",
    "spark_df.printSchema()\n",
    "print(f\"\\nDataFrame info:\")\n",
    "spark_df.rdd.getNumPartitions()\n",
    "print(f\"Number of partitions: {spark_df.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ea1217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows:\n",
      "+-----------------------------+-----------------------+------+-------------------+\n",
      "|TagName                      |EventTime              |Status|Value              |\n",
      "+-----------------------------+-----------------------+------+-------------------+\n",
      "|A2PS64V0J.:ZUX09R            |2024-01-02 20:03:46.000|Good  |0.3400000035762787 |\n",
      "|A2PS64V0J.:ZUX09R            |2024-01-02 16:00:12.000|Good  |0.15000000596046448|\n",
      "|A2PS64V0J.:ZUX09R            |2024-01-02 11:56:42.000|Good  |0.12999999523162842|\n",
      "|A2PS64V0J.:ZUX09R            |2024-01-02 07:53:11.000|Good  |0.11999999731779099|\n",
      "|A2PS64V0J.:ZUX09R            |2024-01-02 03:49:45.000|Good  |0.12999999523162842|\n",
      "|-4O7LSSAM_3EA02:2GT7E02I_R_MP|2024-01-02 20:09:58.053|Good  |7107.82080078125   |\n",
      "|_LT2EPL-9PM0.OROTENV3:       |2024-01-02 12:27:10.518|Good  |19407.0            |\n",
      "|_LT2EPL-9PM0.OROTENV3:       |2024-01-02 05:23:10.143|Good  |19403.0            |\n",
      "|_LT2EPL-9PM0.OROTENV3:       |2024-01-02 01:31:10.086|Good  |19399.0            |\n",
      "|1N325T3MTOR-P0L29:9.T0       |2024-01-02 23:41:10.358|Good  |19376.0            |\n",
      "+-----------------------------+-----------------------+------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "Data types:\n",
      "[('TagName', 'string'), ('EventTime', 'string'), ('Status', 'string'), ('Value', 'string')]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# FIRST LOOK AT DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"First 10 rows:\")\n",
    "spark_df.show(10, truncate=False)\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(spark_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a074d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values (NULL and NaN):\n",
      "+------------------+--------------------+-----------------+----------------+\n",
      "|TagName_null_count|EventTime_null_count|Status_null_count|Value_null_count|\n",
      "+------------------+--------------------+-----------------+----------------+\n",
      "|                 0|                   0|                0|               0|\n",
      "+------------------+--------------------+-----------------+----------------+\n",
      "\n",
      "\n",
      "Value column NaN count: 74,875\n",
      "\n",
      "Missing values percentage:\n",
      "+----------------+------------------+---------------+--------------+\n",
      "|TagName_null_pct|EventTime_null_pct|Status_null_pct|Value_null_pct|\n",
      "+----------------+------------------+---------------+--------------+\n",
      "|             0.0|               0.0|            0.0|           0.0|\n",
      "+----------------+------------------+---------------+--------------+\n",
      "\n",
      "Value column NaN percentage: 0.03%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MISSING VALUES\n",
    "# ============================================================================\n",
    "\n",
    "from pyspark.sql.functions import col, count, when\n",
    "\n",
    "print(\"Missing values (NULL and NaN):\")\n",
    "missing_stats = spark_df.select([\n",
    "    count(when(col(c).isNull(), 1)).alias(f\"{c}_null_count\")\n",
    "    for c in spark_df.columns\n",
    "])\n",
    "missing_stats.show()\n",
    "\n",
    "# Also check for NaN in Value column\n",
    "nan_count = spark_df.filter(isnan(col(\"Value\"))).count()\n",
    "print(f\"\\nValue column NaN count: {nan_count:,}\")\n",
    "\n",
    "print(\"\\nMissing values percentage:\")\n",
    "missing_pct = spark_df.select([\n",
    "    (count(when(col(c).isNull(), 1)) / count(\"*\") * 100).alias(f\"{c}_null_pct\")\n",
    "    for c in spark_df.columns\n",
    "])\n",
    "missing_pct.show()\n",
    "\n",
    "nan_pct = (nan_count / spark_df.count() * 100)\n",
    "print(f\"Value column NaN percentage: {nan_pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8db22167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example rows with NaN values in Value column:\n",
      "+---------------+-----------------------+------+-----+\n",
      "|TagName        |EventTime              |Status|Value|\n",
      "+---------------+-----------------------+------+-----+\n",
      "|1530P2X:VUC0.HB|2024-01-15 09:24:00.000|Bad   |nan  |\n",
      "|1530P2X:VUC0.HB|2024-01-15 09:22:00.000|Bad   |nan  |\n",
      "|1530P2X:VUC0.HB|2024-01-15 12:59:00.000|Bad   |nan  |\n",
      "|1530P2X:VUC0.HB|2024-01-15 12:57:00.000|Bad   |nan  |\n",
      "|1530P2X:VUC0.HB|2024-01-15 12:58:00.000|Bad   |nan  |\n",
      "|1530P2X:VUC0.HB|2024-01-15 09:20:00.000|Bad   |nan  |\n",
      "|1530P2X:VUC0.HB|2024-01-15 09:23:00.000|Bad   |nan  |\n",
      "|1530P2X:VUC0.HB|2024-01-15 09:18:00.000|Bad   |nan  |\n",
      "|1530P2X:VUC0.HB|2024-01-15 07:04:00.000|Bad   |nan  |\n",
      "|1530P2X:VUC0.HB|2024-01-15 07:05:00.000|Bad   |nan  |\n",
      "+---------------+-----------------------+------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExample rows with NaN values in Value column:\")\n",
    "spark_df.filter(isnan(col(\"Value\"))).select(\n",
    "    \"TagName\", \"EventTime\", \"Status\", \"Value\"\n",
    ").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43c117bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "root\n",
      " |-- TagName: string (nullable = true)\n",
      " |-- EventTime: timestamp (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Value: float (nullable = true)\n",
      " |-- Value_Status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### create new column value_status to perform statistics\n",
    "\n",
    "# Create Value_Status column (capture non-numeric values before converting)\n",
    "spark_df = spark_df.withColumn(\n",
    "    \"Value_Status\",\n",
    "    when(col(\"Value\").cast(\"float\").isNull() & col(\"Value\").isNotNull(), col(\"Value\"))\n",
    "    .otherwise(\"Valid\")\n",
    ")\n",
    "\n",
    "# Convert Value to float (non-numeric become null)\n",
    "spark_df = spark_df.withColumn(\"Value\", col(\"Value\").cast(\"float\"))\n",
    "\n",
    "# Convert EventTime to proper timestamp format\n",
    "spark_df = spark_df.withColumn(\"EventTime\", col(\"EventTime\").cast(\"timestamp\"))\n",
    "\n",
    "print(\"Schema:\")\n",
    "spark_df.printSchema()\n",
    "\n",
    "#print(\"\\nValue_Status distribution:\")\n",
    "#spark_df.groupBy(\"Value_Status\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ee22c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique TagNames:\n",
      "+---------------------------+------+\n",
      "|TagName                    |count |\n",
      "+---------------------------+------+\n",
      "|T:4FU4PRBV3NO0V_0PLM40R-.34|553540|\n",
      "|P0TON:H53Y3S.C1CL          |518277|\n",
      "|0.3HN:CPOC5Y18BTPS         |518277|\n",
      "|HO.T:C4F5C0O5U1YN          |518277|\n",
      "|5H4C:S.YPLOTC1N00          |518277|\n",
      "|S.LY7O:3PC0N5T1HC          |518277|\n",
      "|OTHS1:5.TP3C0N9CY          |518277|\n",
      "|4:HTSN1C4T0.CPY5O          |518277|\n",
      "|5.CF:1H45CP0OYSNT          |518277|\n",
      "|H951ASC.MO:YNEQ1I1         |518277|\n",
      "+---------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Total unique TagNames: 7759\n",
      "\n",
      "Unique Status values:\n",
      "+-----------------+---------+\n",
      "|Status           |count    |\n",
      "+-----------------+---------+\n",
      "|Good             |213642667|\n",
      "|Bad              |1347992  |\n",
      "|Substituted, Good|253      |\n",
      "|Questionable     |190      |\n",
      "+-----------------+---------+\n",
      "\n",
      "Total unique Status: 4\n",
      "\n",
      "Value_Status distribution:\n",
      "+-------------+---------+\n",
      "|Value_Status |count    |\n",
      "+-------------+---------+\n",
      "|Valid        |214500000|\n",
      "|Calc Failed  |231627   |\n",
      "|Bad Input    |98155    |\n",
      "|No Result    |47516    |\n",
      "|Failed       |47516    |\n",
      "|Out of Serv  |43917    |\n",
      "|Bad          |19920    |\n",
      "|Scan Timeout |1452     |\n",
      "|Comm Fail    |694      |\n",
      "|I/O Timeout  |208      |\n",
      "|Doubtful     |41       |\n",
      "|Not Connect  |34       |\n",
      "|Pt Created   |12       |\n",
      "|Invalid Float|8        |\n",
      "|Scan Off     |2        |\n",
      "+-------------+---------+\n",
      "\n",
      "Total unique Value_Status: 15\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CATEGORICAL COLUMNS (TagName, Status, Value_Status)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Unique TagNames:\")\n",
    "tag_counts = spark_df.groupBy(\"TagName\").count().orderBy(col(\"count\").desc())\n",
    "tag_counts.show(10, truncate=False)\n",
    "print(f\"Total unique TagNames: {tag_counts.count()}\")\n",
    "\n",
    "print(\"\\nUnique Status values:\")\n",
    "status_counts = spark_df.groupBy(\"Status\").count().orderBy(col(\"count\").desc())\n",
    "status_counts.show(truncate=False)\n",
    "print(f\"Total unique Status: {status_counts.count()}\")\n",
    "\n",
    "print(\"\\nValue_Status distribution:\")\n",
    "value_status_counts = spark_df.groupBy(\"Value_Status\").count().orderBy(col(\"count\").desc())\n",
    "value_status_counts.show(truncate=False)\n",
    "print(f\"Total unique Value_Status: {value_status_counts.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ad75d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 214,991,102\n",
      "Clean rows: 214,500,000\n",
      "Rows dropped: 491,102\n",
      "\n",
      "Clean schema:\n",
      "root\n",
      " |-- TagName: string (nullable = true)\n",
      " |-- EventTime: timestamp (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Value: float (nullable = true)\n",
      "\n",
      "\n",
      "Sample clean data:\n",
      "+--------------------+--------------------+------+--------+\n",
      "|             TagName|           EventTime|Status|   Value|\n",
      "+--------------------+--------------------+------+--------+\n",
      "|   A2PS64V0J.:ZUX09R| 2024-01-02 20:03:46|  Good|    0.34|\n",
      "|   A2PS64V0J.:ZUX09R| 2024-01-02 16:00:12|  Good|    0.15|\n",
      "|   A2PS64V0J.:ZUX09R| 2024-01-02 11:56:42|  Good|    0.13|\n",
      "|   A2PS64V0J.:ZUX09R| 2024-01-02 07:53:11|  Good|    0.12|\n",
      "|   A2PS64V0J.:ZUX09R| 2024-01-02 03:49:45|  Good|    0.13|\n",
      "|-4O7LSSAM_3EA02:2...|2024-01-02 20:09:...|  Good|7107.821|\n",
      "|_LT2EPL-9PM0.OROT...|2024-01-02 12:27:...|  Good| 19407.0|\n",
      "|_LT2EPL-9PM0.OROT...|2024-01-02 05:23:...|  Good| 19403.0|\n",
      "|_LT2EPL-9PM0.OROT...|2024-01-02 01:31:...|  Good| 19399.0|\n",
      "|1N325T3MTOR-P0L29...|2024-01-02 23:41:...|  Good| 19376.0|\n",
      "+--------------------+--------------------+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CREATE CLEAN DATAFRAME (remove NULL and NaN from Value column)\n",
    "# ============================================================================\n",
    "\n",
    "spark_df_clean = spark_df.filter(col(\"Value\").isNotNull()).drop(\"Value_Status\")\n",
    "spark_df_clean = spark_df_clean.withColumn(\"Value\", col(\"Value\").cast(\"float\"))\n",
    "\n",
    "# Remove NaN values\n",
    "spark_df_clean = spark_df_clean.filter(~isnan(col(\"Value\")))\n",
    "\n",
    "print(f\"\\nOriginal rows: {spark_df.count():,}\")\n",
    "print(f\"Clean rows: {spark_df_clean.count():,}\")\n",
    "print(f\"Rows dropped: {spark_df.count() - spark_df_clean.count():,}\")\n",
    "\n",
    "print(\"\\nClean schema:\")\n",
    "spark_df_clean.printSchema()\n",
    "\n",
    "print(\"\\nSample clean data:\")\n",
    "spark_df_clean.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b813431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique TagNames:\n",
      "+---------------------------+------+\n",
      "|TagName                    |count |\n",
      "+---------------------------+------+\n",
      "|T:4FU4PRBV3NO0V_0PLM40R-.34|553540|\n",
      "|P0TON:H53Y3S.C1CL          |518277|\n",
      "|0.3HN:CPOC5Y18BTPS         |518277|\n",
      "|HO.T:C4F5C0O5U1YN          |518277|\n",
      "|5H4C:S.YPLOTC1N00          |518277|\n",
      "|S.LY7O:3PC0N5T1HC          |518277|\n",
      "|OTHS1:5.TP3C0N9CY          |518277|\n",
      "|4:HTSN1C4T0.CPY5O          |518277|\n",
      "|5.CF:1H45CP0OYSNT          |518277|\n",
      "|H951ASC.MO:YNEQ1I1         |518277|\n",
      "+---------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Total unique TagNames: 6529\n",
      "\n",
      "Unique Status values:\n",
      "+-----------------+---------+\n",
      "|Status           |count    |\n",
      "+-----------------+---------+\n",
      "|Good             |213642667|\n",
      "|Bad              |782015   |\n",
      "|Substituted, Good|253      |\n",
      "|Questionable     |190      |\n",
      "+-----------------+---------+\n",
      "\n",
      "Total unique Status: 4\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CATEGORICAL COLUMNS (TagName, Status) after cleaning\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Unique TagNames:\")\n",
    "tag_counts = spark_df_clean.groupBy(\"TagName\").count().orderBy(col(\"count\").desc())\n",
    "tag_counts.show(10, truncate=False)\n",
    "print(f\"Total unique TagNames: {tag_counts.count()}\")\n",
    "\n",
    "print(\"\\nUnique Status values:\")\n",
    "status_counts = spark_df_clean.groupBy(\"Status\").count().orderBy(col(\"count\").desc())\n",
    "status_counts.show(truncate=False)\n",
    "print(f\"Total unique Status: {status_counts.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb2ce9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value statistics (clean data):\n",
      "+-------+--------------------+\n",
      "|summary|               Value|\n",
      "+-------+--------------------+\n",
      "|  count|           214425125|\n",
      "|   mean|-6.90248730437452...|\n",
      "| stddev|7.114647230934678...|\n",
      "|    min|        -7.366718E20|\n",
      "|    max|        6.2658613E12|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# NUMERIC COLUMN (Value) - DESCRIPTIVE STATS\n",
    "# ============================================================================\n",
    "\n",
    "from pyspark.sql.functions import mean, stddev, min as spark_min, max as spark_max, when\n",
    "\n",
    "print(\"Value statistics (clean data):\")\n",
    "spark_df_clean.describe(\"Value\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aed3183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EventTime range:\n",
      "+-------------------+-----------------------+\n",
      "|earliest           |latest                 |\n",
      "+-------------------+-----------------------+\n",
      "|2023-12-31 00:00:00|2024-07-27 23:59:57.573|\n",
      "+-------------------+-----------------------+\n",
      "\n",
      "Duration: 209 days\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TIME SERIES INFO\n",
    "# ============================================================================\n",
    "\n",
    "from pyspark.sql.functions import min as spark_min, max as spark_max, datediff\n",
    "\n",
    "print(\"EventTime range:\")\n",
    "time_stats = spark_df_clean.select(\n",
    "    spark_min(\"EventTime\").alias(\"earliest\"),\n",
    "    spark_max(\"EventTime\").alias(\"latest\")\n",
    ")\n",
    "time_stats.show(truncate=False)\n",
    "\n",
    "earliest = spark_df_clean.agg(spark_min(\"EventTime\")).collect()[0][0]\n",
    "latest = spark_df_clean.agg(spark_max(\"EventTime\")).collect()[0][0]\n",
    "duration_days = (latest - earliest).days\n",
    "print(f\"Duration: {duration_days} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3108e1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records per TagName:\n",
      "+---------------------------+------+\n",
      "|TagName                    |count |\n",
      "+---------------------------+------+\n",
      "|T:4FU4PRBV3NO0V_0PLM40R-.34|553540|\n",
      "|CHP.1TSA:OCN0P358Y         |518277|\n",
      "|5H4C:S.YPLOTC1N00          |518277|\n",
      "|2C4O5H01TS:Y.NPCF          |518277|\n",
      "|C.OH0TU:C1Y4HON35          |518277|\n",
      "|0:HC5Y013CP.SOTTN          |518277|\n",
      "|H951ASC.MO:YNEQ1I1         |518277|\n",
      "|YOP3T5.NC:112HSCT          |518277|\n",
      "|5.CF:1H45CP0OYSNT          |518277|\n",
      "|4:HTSN1C4T0.CPY5O          |518277|\n",
      "|0.3HN:CPOC5Y18BTPS         |518277|\n",
      "|:PCT01SN0LH.5Y3CO          |518277|\n",
      "|P0TON:H53Y3S.C1CL          |518277|\n",
      "|S:CF5PO.5H03Y1NTC          |518277|\n",
      "|10YLCH3NS:.PTOC55          |518277|\n",
      "+---------------------------+------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RECORDS PER TAG\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Records per TagName:\")\n",
    "records_per_tag = spark_df_clean.groupBy(\"TagName\").count().orderBy(col(\"count\").desc())\n",
    "records_per_tag.show(15, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65fd29ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records by year:\n",
      "+---------------+---------+\n",
      "|year(EventTime)|    count|\n",
      "+---------------+---------+\n",
      "|           2023|  1086413|\n",
      "|           2024|213338712|\n",
      "+---------------+---------+\n",
      "\n",
      "\n",
      "Records by month (last 12 months):\n",
      "+---------------+----------------+--------+\n",
      "|year(EventTime)|month(EventTime)|   count|\n",
      "+---------------+----------------+--------+\n",
      "|           2024|               7|27521992|\n",
      "|           2024|               6|29788540|\n",
      "|           2024|               5|31597385|\n",
      "|           2024|               4|30520851|\n",
      "|           2024|               3|31533923|\n",
      "|           2024|               2|29902461|\n",
      "|           2024|               1|32473560|\n",
      "|           2023|              12| 1086413|\n",
      "+---------------+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# RECORDS OVER TIME\n",
    "# ============================================================================\n",
    "\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour\n",
    "\n",
    "print(\"Records by year:\")\n",
    "spark_df_clean.groupBy(year(\"EventTime\")).count().orderBy(\"year(EventTime)\").show()\n",
    "\n",
    "print(\"\\nRecords by month (last 12 months):\")\n",
    "spark_df_clean.groupBy(year(\"EventTime\"), month(\"EventTime\")).count().orderBy(col(\"year(EventTime)\").desc(), col(\"month(EventTime)\").desc()).show(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cdda83cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Value by TagName:\n",
      "+-----------------------+--------------------+---------+------------+---------------------+\n",
      "|TagName                |avg_value           |min_value|max_value   |stddev_value         |\n",
      "+-----------------------+--------------------+---------+------------+---------------------+\n",
      "|.3XVL3TP3:295PFX       |1.4524630515993804E8|3.3175936|6.2658613E12|3.0161312472654926E10|\n",
      "|COG3NF02RQA7P0D.1:TV_CT|7132779.659987816   |5852479.0|8318120.5   |733436.6184894337    |\n",
      "|C_TGD00:R7QA2VF1T.OCPN3|5910953.948570976   |302.0    |7861627.5   |1112582.0924773156   |\n",
      "|TCF3O.RQ_:2AV01GP07DCNT|4098994.2432386125  |313.0    |5852479.0   |1061281.3811492713   |\n",
      "|TA7F_2TPGCQ3DC:.OR1N0V0|3547827.2700363146  |0.0      |9022103.0   |3511438.738997856    |\n",
      "|3QDRNC._:A7F2CGTOT0V0P1|3297653.7527593696  |0.0      |9024536.0   |3520902.7952661323   |\n",
      "|NCAF_7P0T.CRDT103V2:GQO|3195330.259663534   |1956780.5|4424218.5   |721799.0720803908    |\n",
      "|NG1VATP2DFO_C3T00.7:RCQ|2465483.455718564   |881127.25|4014900.8   |901677.0370580605    |\n",
      "|U1U.L0WHC1S0U1C3M:     |786976.7293841869   |683323.9 |836739.25   |45765.23879281168    |\n",
      "|SMW13011:UUL.HC0UC     |600077.5078061224   |530718.9 |683323.9    |42730.11171455813    |\n",
      "+-----------------------+--------------------+---------+------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VALUE DISTRIBUTION BY TAG\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Average Value by TagName:\")\n",
    "value_by_tag = spark_df_clean.groupBy(\"TagName\").agg(\n",
    "    mean(\"Value\").alias(\"avg_value\"),\n",
    "    spark_min(\"Value\").alias(\"min_value\"),\n",
    "    spark_max(\"Value\").alias(\"max_value\"),\n",
    "    stddev(\"Value\").alias(\"stddev_value\")\n",
    ").orderBy(col(\"avg_value\").desc())\n",
    "value_by_tag.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d215ab03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value statistics by Status:\n",
      "+-----------------+---------+---------------------+------------+------------+---------------------+\n",
      "|Status           |count    |avg_value            |min_value   |max_value   |stddev_value         |\n",
      "+-----------------+---------+---------------------+------------+------------+---------------------+\n",
      "|Good             |213642667|-6.927767397004301E12|-7.366718E20|6.2658613E12|7.1276638835902336E16|\n",
      "|Bad              |782015   |281.0936158513583    |238.0       |317.0       |30.63950909112452    |\n",
      "|Substituted, Good|253      |27558.52905172887    |-43.131046  |381496.12   |90485.9167599752     |\n",
      "|Questionable     |190      |15.39002905770352    |0.0         |202.5       |21.104189224728955   |\n",
      "+-----------------+---------+---------------------+------------+------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VALUE DISTRIBUTION BY STATUS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Value statistics by Status:\")\n",
    "value_by_status = spark_df_clean.groupBy(\"Status\").agg(\n",
    "    count(\"Value\").alias(\"count\"),\n",
    "    mean(\"Value\").alias(\"avg_value\"),\n",
    "    spark_min(\"Value\").alias(\"min_value\"),\n",
    "    spark_max(\"Value\").alias(\"max_value\"),\n",
    "    stddev(\"Value\").alias(\"stddev_value\")\n",
    ").orderBy(col(\"count\").desc())\n",
    "value_by_status.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b8f409e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers (>3 std devs): 6\n",
      "Outlier percentage: 0.00%\n",
      "\n",
      "Sample outliers:\n",
      "+---------------+-------------------+--------------+------+\n",
      "|        TagName|          EventTime|         Value|Status|\n",
      "+---------------+-------------------+--------------+------+\n",
      "|V0R0.:0X715PNSX|2024-02-08 02:30:22|-1.64307321E18|  Good|\n",
      "|0N:P7RXV031S0.X|2024-02-08 02:31:13|-1.64307321E18|  Good|\n",
      "|0N:P7RXV031S0.X|2024-02-08 02:30:17|-1.64307321E18|  Good|\n",
      "|VX0XN07P1.1:3RS|2024-02-08 02:31:13|  -7.366718E20|  Good|\n",
      "|V0R0.:0X715PNSX|2024-02-08 02:31:18|-1.64307321E18|  Good|\n",
      "|VX0XN07P1.1:3RS|2024-02-08 02:30:17|  -7.366718E20|  Good|\n",
      "+---------------+-------------------+--------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# OUTLIER DETECTION (Values > 3 std devs from mean)\n",
    "# ============================================================================\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "mean_val = spark_df_clean.agg(mean(\"Value\")).collect()[0][0]\n",
    "stddev_val = spark_df_clean.agg(stddev(\"Value\")).collect()[0][0]\n",
    "\n",
    "outlier_threshold_high = mean_val + (3 * stddev_val)\n",
    "outlier_threshold_low = mean_val - (3 * stddev_val)\n",
    "\n",
    "outliers = spark_df_clean.filter((col(\"Value\") > outlier_threshold_high) | (col(\"Value\") < outlier_threshold_low))\n",
    "print(f\"Outliers (>3 std devs): {outliers.count():,}\")\n",
    "print(f\"Outlier percentage: {outliers.count() / spark_df_clean.count() * 100:.2f}%\")\n",
    "print(\"\\nSample outliers:\")\n",
    "outliers.select(\"TagName\", \"EventTime\", \"Value\", \"Status\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba5ab998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Report:\n",
      "Total records: 214,425,125\n",
      "Duplicate records (all columns): 1,572\n",
      "Records with null Value: 0\n",
      "Records with null EventTime: 0\n",
      "Records with null TagName: 0\n",
      "Records with null Status: 0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATA QUALITY ISSUES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Data Quality Report:\")\n",
    "print(f\"Total records: {spark_df_clean.count():,}\")\n",
    "print(f\"Duplicate records (all columns): {spark_df_clean.count() - spark_df_clean.dropDuplicates().count():,}\")\n",
    "print(f\"Records with null Value: {spark_df_clean.filter(col('Value').isNull()).count():,}\")\n",
    "print(f\"Records with null EventTime: {spark_df_clean.filter(col('EventTime').isNull()).count():,}\")\n",
    "print(f\"Records with null TagName: {spark_df_clean.filter(col('TagName').isNull()).count():,}\")\n",
    "print(f\"Records with null Status: {spark_df_clean.filter(col('Status').isNull()).count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6377bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of data with unix timestamp for correlation analysis:\n",
      "+-----------------+-------------------+--------------+-----+\n",
      "|          TagName|          EventTime|timestamp_unix|Value|\n",
      "+-----------------+-------------------+--------------+-----+\n",
      "|A2PS64V0J.:ZUX09R|2024-01-02 20:03:46|    1704222226| 0.34|\n",
      "|A2PS64V0J.:ZUX09R|2024-01-02 16:00:12|    1704207612| 0.15|\n",
      "|A2PS64V0J.:ZUX09R|2024-01-02 11:56:42|    1704193002| 0.13|\n",
      "|A2PS64V0J.:ZUX09R|2024-01-02 07:53:11|    1704178391| 0.12|\n",
      "|A2PS64V0J.:ZUX09R|2024-01-02 03:49:45|    1704163785| 0.13|\n",
      "+-----------------+-------------------+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CORRELATION BETWEEN VALUE AND TIME (by tag)\n",
    "# ============================================================================\n",
    "\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "\n",
    "print(\"Sample of data with unix timestamp for correlation analysis:\")\n",
    "spark_df_ts = spark_df_clean.withColumn(\"timestamp_unix\", unix_timestamp(\"EventTime\"))\n",
    "spark_df_ts.select(\"TagName\", \"EventTime\", \"timestamp_unix\", \"Value\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b5a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaca242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtdip-sdk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
